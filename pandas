##################################### pandas ##############################################
import pandas as pd
population = pd.Series([51470000, 327200000, 129200000, 37060000], index=['Korea','America','Mexico','Canada'], name = 'Country')
population
#Korea       51470000
#America    327200000
#Mexico     129200000
#Canada      37060000
#Name: Country, dtype: int64

index = ['Korea','America','Mexico','Canada']
birth_rate = pd.Series([1.17,1.80,2.18,1.60], index = index, name='Birth rate(per woman)')
unemployment_rate = pd.Series([0.044,0.036,0.034,0.057], index = index, name='Unemployment rate')

df_countries = pd.DataFrame({'Population':population,
                            'Birth rate':birth_rate,
                            'Unemployment rate': unemployment_rate})
df_countries

#             Population	Birth rate	Unemployment rate
#Korea	       51470000	1.17	       0.044
#America	327200000	1.80	       0.036
#Mexico	129200000	2.18	       0.034
#Canada	37060000	1.60	       0.057

print(df_countries.shape)
print(df_countries.columns)
#(4, 3)
#Index(['Population', 'Birth rate', 'Unemployment rate'], dtype='object')

df_countries_2 = pd.DataFrame([[51470000, 1.17, 0.044],
                             [327200000, 1.80, 0.036],
                             [129200000, 2.18, 0.034],
                             [37060000, 1.60, 0.057]],
                           index = ['Korea','America','Mexico','Canada'],
                           columns = ['Population', 'Birth rate','Unemployment rate'])
df_countries_2
#             Population	Birth rate	Unemployment rate
#Korea	       51470000	1.17	       0.044
#America	327200000	1.80	       0.036
#Mexico	129200000	2.18	       0.034
#Canada	37060000	1.60	       0.057

json_data = [
    {"Name": "Korea","Population": 51470000, "Birth rate": 1.17, "Unemployment rate": 0.044},
    {"Name": "America","Population": 327200000, "Birth rate": 1.80, "Unemployment rate": 0.036},
    {"Name": "Mexico","Population": 129200000, "Birth rate": 2.18, "Unemployment rate": 0.034},
    {"Name": "Canada","Population": 37060000, "Birth rate": 1.60, "Unemployment rate": 0.057}
]
df_countries_3 = pd.DataFrame.from_dict(json_data)
df_countries_3
#	Birth rate	Name	       Population	Unemployment rate
#0	1.17	       Korea	       51470000	0.044
#1	1.80	       America	327200000	0.036
#2	2.18	       Mexico	       129200000	0.034
#3	1.60	       Canada	       37060000	0.057

df_countries_3 = df_countries_3.set_index("Name")
df_countries_3
#	       Birth rate	Population	Unemployment rate
#Name			
#Korea	       1.17	       51470000	0.044
#America	1.80	       327200000	0.036
#Mexico	2.18	       129200000	0.034
#Canada	1.60	       37060000	0.057

df_countries_3.reset_index()
#	Birth rate	Name	       Population	Unemployment rate
#0	1.17	       Korea	       51470000	0.044
#1	1.80	       America	327200000	0.036
#2	2.18	       Mexico	       129200000	0.034
#3	1.60	       Canada	       37060000	0.057

df_countries_3.reset_index().reindex([2,1,3,0],columns=['Birth rate','Population','Unemployment rate'])
# change order of index
# should have reset_index(). if not, values are NaN

#	Birth rate	Population	Unemployment rate
#2	2.18	       129200000	0.034
#1	1.80	       327200000	0.036
#3	1.60	       37060000	0.057
#0	1.17	       51470000	0.044

df_countries_3.sort_values('Unemployment rate', ascending = False)

df_countries_3.sort_index(ascending = False)

df_countries_3.rank()
#	       Birth rate	Population	Unemployment rate
#Name			
#Korea	       1.0	       2.0	       3.0
#America	3.0	       4.0	       2.0
#Mexico	4.0	       3.0	       1.0
#Canada	2.0	       1.0	       4.0

df_countries_3.rename(index = {'Korea':'South Korea'},columns={'Birth rate': 'Birth rate(per woman)'})
#	       Birth rate(per woman)	Population	Unemployment rate
#Name			
#South Korea	1.17	                     51470000	0.044
#America	1.80	                     327200000	0.036
#Mexico	2.18	                     129200000	0.034
#Canada	1.60	                     37060000	0.057

df_dtype.head()
df_dtype.tail()
df_dtype.sample(n=5) # get n parts of row ramdomly

df_dtype.sample(frac=0.1) # get by ratio
# ex. 20 rows, fac=0.1 so 10% = 2
#	Age	Sex	Height	Weight	Favorite Food
#Number					
#11	26	2	162	59	1
#13	35	1	173	68	3

df_dtype[2:5]
df_dtype[['Favorite Food','Sex']]
df_dtype > 2 # shows dataframe. True or False values

df_dtype['Sex'] == 1

#1      True
#2     False
#3      True
# ...

df_dtype[df_dtype['Sex']==1] # shows only rows that if Sex == 1
#	Age	Sex	Height	Weight	Favorite Food
#Number					
#1	30	1	183	82	1
#3	27	1	178	77	2
# ...

df_dtype.where(df_dtype['Sex']>1)
#      Age	Sex	Height	Weight	Favorite Food
#Number					
#1	NaN	NaN	NaN	NaN	NaN
#2	28.0	2	160.0	62.0	3

df_dtype.where(df_dtype > 1)

s = pd.Series([70,80,90,100])
g = {70: "C", 80:"B", 90:"A",100:"A+"}
s.map(g)
#0     C
#1     B
#2     A
#3    A+

s = pd.Series([26,13,17,31,7,20])
s.map(lambda x: round(x, -1))
#0    30
#1    10
#2    20
#3    30
#4    10
#5    20

s.apply(lambda x: round(x, -1))
# apply and map don't change data. return copy of changed data

df_food = pd.DataFrame([('Korean', 7),('American', 33),('Italian', 15)], index=[1,2,3],columns=['Food type','Numbers of restaurant'])
new_df = pd.merge(df_dtype, df_food, left_on='Favorite Food', right_index = True)
new_df.sort_index()

df_food = pd.DataFrame([(1,'Korean', 7),(2,'American', 33),(3,'Italian', 15)],columns=['Favorite Food','Food type','Numbers of restaurant'])
n_df = pd.merge(df_dtype, df_food, on='Favorite Food')
n_df


df_left = pd.DataFrame([('A','Apple'),('B','Boy'),('D','David'),('F','Father'),('H','Happy'),('J',"Jason")], columns =['Key','LeftWord'])
df_left
df_right = pd.DataFrame([('B','Bed'),('C',"Cat"),('D','Dream'),('E','Elephant'),('H','Hair'),('I','Idea')],columns=['Key','RightWord'])
df_right
pd.merge(df_left, df_right, on='Key',how='inner')
#	Key	LeftWord	RightWord
#0	B	Boy	       Bed
#1	D	David	       Dream
#2	H	Happy	       Hair

pd.merge(df_left,df_right,on='Key',how='left')
#	Key	LeftWord	RightWord
#0	A	Apple	       NaN
#1	B	Boy	       Bed
#2	D	David	       Dream
#3	F	Father	       NaN
#4	H	Happy	       Hair
#5	J	Jason	       NaN

pd.merge(df_left,df_right,on='Key',how='right')
pd.merge(df_left,df_right,on='Key',how='outer')
#	Key	LeftWord	RightWord
#0	A	Apple	       NaN
#1	B	Boy	       Bed
#2	D	David	       Dream
#3	F	Father	       NaN
#4	H	Happy	       Hair
#5	J	Jason	       NaN
#6	C	NaN	       Cat
#7	E	NaN	       Elephant
#8	I	NaN	       Idea

######################### pivot table ########################

pd.pivot_table(df_dtype,index=['Sex'])
#	Age	       Height	       Weight
#Sex			
#1	27.714286	174.071429	72.285714
#2	30.500000	161.333333	61.000000
pd.pivot_table(df_dtype, columns=['Sex'])

pd.pivot_table(df_dtype, index=['Sex'],values='Weight')
#	Weight
#Sex	
#1	72.285714
#2	61.000000

pd.pivot_table(df_dtype, columns='Sex', index='Favorite Food', values=['Weight'], aggfunc = np.median)
# aggfunc(aggregation function) if no assign to aggfunc, default aggfunc is np.mean
#	       Weight
#Sex	       1	2
#Favorite Food		
#1	       77.0	57.0
#2	       70.0	60.0
#3	       70.5	62.0

pd.pivot_table(df_dtype, columns='Sex', index='Favorite Food', values=['Weight'], aggfunc = np.median)

data = pd.DataFrame([('A','T','Y'),('A','F','Y'),('B','T','N'),('B','F','N')],columns=['Alphabet','TorF',"YorN"])
data

pd.pivot_table(data, index='Alphabet',columns='TorF',values='YorN',aggfunc=lambda x:x)
# must have aggfunc = lambda x:x
#TorF	       F	T
#Alphabet		
#A	       Y	Y
#B	       N	N

###### melt ---> oposite of pivot table #####

df_pivot = pd.pivot_table(df_dtype, index='Sex',columns='Favorite Food', values='Weight',aggfunc=np.median)
df_pivot

#Favorite Food	1	2	3
#Sex			
#1	              77.0	70.0	70.5
#2	              57.0	60.0	62.0

df_pivot.index
#Int64Index([1, 2], dtype='int64', name='Sex')

df_pivot = df_pivot.reset_index()
pd.melt(df_pivot, id_vars=["Sex"])

#      Sex	Favorite Food	       value
#0	1	1	              77.0
#1	2	1	              57.0
#2	1	2	              70.0
#3	2	2	              60.0
#4	1	3	              70.5
#5	2	3	              62.0

###### Series ##################

obj = pd.Series([3,1,-2,9])
obj
#0    3
#1    1
#2   -2
#3    9
#dtype: int64

obj.values
#array([ 3,  1, -2,  9], dtype=int64)

obj.index
#RangeIndex(start=0, stop=4, step=1)

obj.dtype
#dtype('int64')

# can change index
obj2 = pd.Series([3,1,-2,9], index=['a','b','c','d'])
obj2
#a    3
#b    1
#c   -2
#d    9
#dtype: int64

data = {'David': 28000, 'Kim':33000, 'Tom': 19000, 'Jack':23000}
obj3 = pd.Series(data)
obj3
#David    28000
#Kim      33000
#Tom      19000
#Jack     23000
#dtype: int64

obj3.name = 'Salary'
obj3.index.name = 'Names'
obj3
#Names
#David    28000
#Kim      33000
#Tom      19000
#Jack     23000
#Name: Salary, dtype: int64

obj3.index = ['a','b','c','d']
obj3
#a    28000
#b    33000
#c    19000
#d    23000
#Name: Salary, dtype: int64

############################### Data Frame ######################

data = {'name': ['Brian','Christian','Daniel','Daniel','Daniel'],
       'year': [2017,2016,2016,2017,2018],
       'point': [2.7,3.1,2.1,2.7,3.3]}
df = pd.DataFrame(data)
df
#   name	    year	point
#0	Brian 	  2017	2.7
#1	Christian	2016	3.1
#2	Daniel	  2016	2.1
#3	Daniel	  2017	2.7
#4	Daniel	  2018	3.3

### rows
df.index
#RangeIndex(start=0, stop=5, step=1)

### columns
df.columns
#Index(['name', 'year', 'point'], dtype='object')

df.values
#array([['Brian', 2017, 2.7],
#       ['Christian', 2016, 3.1],
#       ['Daniel', 2016, 2.1],
#       ['Daniel', 2017, 2.7],
#       ['Daniel', 2018, 3.3]], dtype=object)

df.index.name = 'Num'
df.columns.name = 'Info'
df
#Info	  name	    year	point
#Num			
#0	    Brian	    2017	2.7
#1	    Christian	2016	3.1
#2	    Daniel	  2016	2.1
#3	    Daniel	  2017	2.7
#4	    Daniel	  2018	3.3

df2 = pd.DataFrame(data, columns=['year','name','point','penalty'], 
                   index = ['one','two','three','four','five'])
df2
#       year	name	       point	  penalty
#one	  2017	Brian	       2.7	  NaN
#two	  2016	Christian	3.1	  NaN
#three	2016	Daniel	       2.1	  NaN
#four	  2017	Daniel	       2.7	  NaN
#five	  2018	Daniel	       3.3	  NaN

df2.describe()
#       year	      point
#count	5.00000	5.000000
#mean	  2016.80000	2.780000
#std	  0.83666	0.460435
#min	  2016.00000	2.100000
#25%	  2016.00000	2.700000
#50%	  2017.00000	2.700000
#75%	  2017.00000	3.100000
#max	  2018.00000	3.300000


############ DataFrame Indexing #############################

df2
#             year	name	       point	penalty
# one	       2017	Brian	       2.7	  NaN
# two	       2016	Christian	3.1	  NaN
# three	2016	Daniel	       2.1	  NaN
# four	       2017	Daniel	       2.7	  NaN
# five	       2018	Daniel	       3.3	  NaN

df2['year']
#one      2017
#two      2016
#three    2016
#four     2017
#five     2018
#Name: year, dtype: int64

df2.year
#one      2017
#two      2016
#three    2016
#four     2017
#five     2018
#Name: year, dtype: int64

df2[['year','point']]
#       year	point
#one	  2017	2.7
#two	  2016	3.1
#three	2016	2.1
#four	  2017	2.7
#five	  2018	3.3

df2['penalty'] = 0.5
df2
#       year	name	       point	penalty
#one	  2017	Brian	       2.7	  0.5
#two	  2016	Christian	3.1	  0.5
#three	  2016	Daniel	       2.1	  0.5
#four	  2017	Daniel	       2.7	  0.5
#five	  2018	Daniel	       3.3	  0.5

df2['penalty'] = [0.2,0.3,0.2,0.5,0.3]
df2
#        year	       name	    point	penalty
#one 	   2017	Brian	       2.7	  0.2
#two	   2016	Christian	3.1	  0.3
#three	   2016	Daniel	       2.1	  0.2
#four	   2017	Daniel	       2.7	  0.5
#five	   2018	Daniel	       3.3	  0.3

df2['number'] = np.arange(1,6)
df2
#        year	name	       point	penalty       number
#one	  2017	Brian	       2.7    0.2	    1
#two	  2016	Christian	3.1 	0.3	    2
#three	  2016	Daniel	       2.1	0.2	    3
#four	  2017	Daniel	       2.7 	0.5	    4
#five 	  2018	Daniel	       3.3	0.3	    5

val = pd.Series([-0.3,-0.5,-0.1], index=['two','three','five'])
df2['debt'] = val
df2
#       year	  name	       point	    penalty	number	       debt
#one	  2017	Brian	       2.7	      0.2	    1	      NaN
#two	  2016	Christian	3.1	      0.3	    2	      -0.3
#three	  2016	Daniel	       2.1	      0.2	    3	      -0.5
#four	  2017	Daniel	       2.7	      0.5	    4	      NaN
#five	  2018	Daniel	       3.3	      0.3	    5	      -0.1

df = df2
df
#       year	name	    point	  penalty	number	debt
#one	  2017	Brian	    2.7	    0.2	    1	      NaN
#two	  2016	Christian	3.1	    0.3	    2	      -0.3
#three	2016	Daniel	   2.1	  0.2	    3	      -0.5
#four	  2017	Daniel	  2.7	    0.5	    4	      NaN
#five	  2018	Daniel	  3.3	    0.3	    5	      -0.1

df['net_point'] = df['point'] - df['penalty']
df
#       year	name	      point	penalty	number	debt	net_point
#one	  2017	Brian	      2.7	  0.2	    1	      NaN	    2.5
#two	  2016	Christian	  3.1	  0.3	    2	      -0.3	  2.8
#three	2016	Daniel	    2.1	  0.2	    3	      -0.5	  1.9
#four	  2017	Daniel	    2.7	  0.5	    4	      NaN	    2.2
#five	  2018	Daniel	    3.3	  0.3	    5	      -0.1	  3.0

df['high_point'] = df['net_point'] > 2.5
df
#       year	name	    point	penalty	number	debt	net_point	high_point
#one	  2017	Brian	    2.7	    0.2	    1	    NaN	    2.5	    False
#two	  2016	Christian	3.1	    0.3	    2	    -0.3	  2.8	    True
#three	2016	Daniel	  2.1	    0.2	    3	    -0.5	  1.9	    False
#four	  2017	Daniel	  2.7	    0.5	    4	    NaN	    2.2	    False
#five	  2018	Daniel	  3.3	    0.3	    5	    -0.1	  3.0	    True

del df['high_point']
del df['net_point']
del df['number']
df
#       year	name	    point	penalty	debt
#one	  2017	Brian	    2.7	    0.2	  NaN
#two	  2016	Christian	3.1	    0.3	  -0.3
#three	2016	Daniel	  2.1	    0.2	  -0.5
#four	  2017	Daniel	  2.7	    0.5	  NaN
#five	  2018	Daniel	  3.3	    0.3	  -0.1

df.columns
Index(['year', 'name', 'point', 'penalty', 'debt'], dtype='object')

df.index.name = 'Order'
df.columns.name = 'Info'
df
#Info	  year	name	    point	penalty	debt
#Order					
#one	  2017	Brian	    2.7	  0.2	    NaN
#two	  2016	Christian	3.1 	0.3	    -0.3
#three	2016	Daniel	  2.1	  0.2	    -0.5
#four	  2017	Daniel	  2.7 	0.5	    NaN
#five	  2018	Daniel	  3.3	  0.3	    -0.1

df[0:3]
Info	  year	name	    point	penalty	debt
#Order					
#one	  2017	Brian	    2.7	   0.2	  NaN
#two	  2016	Christian	3.1	  0.3	    -0.3
#three	2016	Daniel	  2.1	  0.2	    -0.5

df.loc['two']
#Info
#year            2016
#name       Christian
#point            3.1
#penalty          0.3
#debt            -0.3
#Name: two, dtype: object

df.loc['two':'four']
#Info	  year	name	       point	penalty	  debt
#Order					
#two	  2016	Christian	3.1	    0.3	  -0.3
#three	  2016	Daniel	       2.1	    0.2	  -0.5
#four	  2017	Daniel	       2.7	    0.5 	  NaN

df.loc['two':'four', 'point']
#Order
#two      3.1
#three    2.1
#four     2.7
#Name: point, dtype: float64

df.loc[:,'year']
#Order
#one      2017
#two      2016
#three    2016
#four     2017
#five     2018
#Name: year, dtype: int64

df['year']
#Order
#one      2017
#two      2016
#three    2016
#four     2017
#five     2018
#Name: year, dtype: int64

df.loc[:,['year','name']]
#Info	  year	name
#Order		
#one	  2017	Brian
#two	  2016	Christian
#three	2016	Daniel
#four	  2017	Daniel
#five	  2018	Daniel
df.loc['three':'five','year':'point']
#Info	  year	name	point
#Order			
#three	2016	Daniel	2.1
#four	  2017	Daniel	2.7
#five	  2018	Daniel	3.3

df.loc['six'] = [2015, 'Shawn', 3.0, 0.2, 0.7]
df
#Info	year	name	       point	penalty	debt
#Order					
#one	2017	Brian	       2.7	0.2	       NaN
#two	2016	Christian	3.1	0.3	       -0.3
#three	2016	Daniel	       2.1	0.2	       -0.5
#four	2017	Daniel	       2.7	0.5	       NaN
#five	2018	Daniel	       3.3	0.3	       -0.1
#six	2015	Shawn	       3.0	0.2	       0.7
 
### df.iloc[index]
df.iloc[3] ### 4th row
#Info
#year         2017
#name       Daniel
#point         2.7
#penalty       0.5
#debt          NaN
#Name: four, dtype: object
df.iloc[3:5,0:2]
#Info	year	name
#Order		
#four	2017	Daniel
#five	2018	Daniel

df.iloc[[0,2,3],[0,1,4]]
#Info	year	name	debt
#Order			
#one	2017	Brian	NaN
#three	2016	Daniel	-0.5
#four	2017	Daniel	NaN
df.iloc[:,1:4]
#Info	name	point	penalty
#Order			
#one	Brian	2.7	0.2
#two	Christian	3.1	0.3
#three	Daniel	2.1	0.2
#four	Daniel	2.7	0.5
#five	Daniel	3.3	0.3
#six	Shawn	3.0	0.2

df.iloc[1,1]
#'Christian'

##################### boolean indexing from DataFrame

df
#Info	  year	 name	       point	penalty	debt
#Order					
#one	  2017	Brian	       2.7	  0.2	    NaN
#two	  2016	Christian	3.1	  0.3	    -0.3
#three	  2016	Daniel	       2.1	  0.2	    -0.5
#four	  2017	Daniel	       2.7	  0.5	    NaN
#five	  2018	Daniel	       3.3	  0.3	    -0.1
#six	  2015	Shawn	       3.0	  0.2	    0.7

df['year'] > 2016
#Order
#one       True
#two      False
#three    False
#four      True
#five      True
#six      False
#Name: year, dtype: bool

df.loc[df['year']>2016, :]
#Info	year	name	  point  penalty	debt
#Order					
#one	2017	Brian	  2.7	  0.2	    NaN
#four	2017	Daniel	  2.7	  0.5	    NaN
#five	2018	Daniel	  3.3	  0.3	    -0.1

df.loc[df['name']=='Daniel',['name','point']]
#Info	  name	point
#Order		
#three	Daniel	2.1
#four	  Daniel	2.7
#five	  Daniel	3.3

df.loc[(df['point'] > 2.3) & (df['point'] < 3.0)]
#Info	year	name	  point	penalty	debt
#Order					
#one	2017	Brian	  2.7	  0.2	    NaN
#four	2017	Daniel	2.7	  0.5	    NaN

df.loc[df['point'] >= 3.0, 'penalty'] = 0
df
#Info	  year	name	    point	penalty	debt
#Order					
#one	  2017	Brian	    2.7	  0.2	    NaN
#two	  2016	Christian	3.1	  0.0	    -0.3
#three	2016	Daniel	  2.1	  0.2	    -0.5
#four	  2017	Daniel	  2.7	  0.5	    NaN
#five	  2018	Daniel	  3.3	  0.0	    -0.1
#six	  2015	Shawn	    3.0	  0.0	    0.7

############################## Data ####################################################

df = pd.DataFrame(np.random.randn(6,4))
df
#   0	          1	          2	          3 
#0	0.593298	  -1.412290	  -0.008338	  -0.069484
#1	-0.157972	  -0.690623	  1.511215	  1.441260
#2	0.515979	  -2.261321	  -2.273262	  1.047784
#3	-0.875186	  0.168660	  -0.541034	  0.078198
#4	0.433342	  -1.766760	  0.679862	  -0.006061
#5	-0.757228	  -1.345091	  -1.260911	  -0.097794

df.columns = ['A','B','C','D']
df.index = pd.date_range('20190501', periods = 6)
df.index
#DatetimeIndex(['2019-05-01', '2019-05-02', '2019-05-03', '2019-05-04',
#               '2019-05-05', '2019-05-06'],
#              dtype='datetime64[ns]', freq='D')

df
#             A	        B	        C	        D
#2019-05-01	  0.593298	-1.412290	-0.008338	-0.069484
#2019-05-02	  -0.157972	-0.690623	1.511215	1.441260
#2019-05-03	  0.515979	-2.261321	-2.273262	1.047784
#2019-05-04	  -0.875186	0.168660	-0.541034	0.078198
#2019-05-05	  0.433342	-1.766760	0.679862	-0.006061
#2019-05-06	  -0.757228	-1.345091	-1.260911	-0.097794
 ### np.nan = NaN

df['F'] = [2.3, np.nan, 1.1, 5.7, np.nan, 3.6] # np.nan = NaN
df
#             A	          B	          C	          D	          F
#2019-05-01	  0.593298	  -1.412290	  -0.008338	  -0.069484	  2.3
#2019-05-02	  -0.157972	  -0.690623	  1.511215	  1.441260	  NaN
#2019-05-03	  0.515979	  -2.261321	  -2.273262	  1.047784	  1.1
#2019-05-04	  -0.875186	  0.168660	  -0.541034	  0.078198	  5.7
#2019-05-05	  0.433342	  -1.766760	  0.679862	  -0.006061	  NaN
#2019-05-06	  -0.757228	  -1.345091	  -1.260911	  -0.097794	  3.6

df.dropna(how = 'any') # remove row if any value of the row is nan
#             A	      B	        C	        D	          F
#2019-05-01	0.593298	-1.412290	-0.008338	-0.069484	2.3
#2019-05-03	0.515979	-2.261321	-2.273262	1.047784	1.1
#2019-05-04	-0.875186	0.168660	-0.541034	0.078198	5.7
#2019-05-06	-0.757228	-1.345091	-1.260911	-0.097794	3.6

df.dropna(how='all') # remove row if all values of the row are nan
#           A	          B	        C	        D	        F
#2019-05-01	0.593298	-1.412290	-0.008338	-0.069484	2.3
#2019-05-02	-0.157972	-0.690623	1.511215	1.441260	NaN
#2019-05-03	0.515979	-2.261321	-2.273262	1.047784	1.1
#2019-05-04	-0.875186	0.168660	-0.541034	0.078198	5.7
#2019-05-05	0.433342	-1.766760	0.679862	-0.006061	NaN
#2019-05-06	-0.757228	-1.345091	-1.260911	-0.097794	3.6

df.fillna(value = 0.7)
#           A	          B	          C     	D	        F
#2019-05-01	0.593298	-1.412290	-0.008338	-0.069484	2.3
#2019-05-02	-0.157972	-0.690623	1.511215	1.441260	0.7
#2019-05-03	0.515979	-2.261321	-2.273262	1.047784	1.1
#2019-05-04	-0.875186	0.168660	-0.541034	0.078198	5.7
#2019-05-05	0.433342	-1.766760	0.679862	-0.006061	0.7
#2019-05-06	-0.757228	-1.345091	-1.260911	-0.097794	3.6
df.isnull()
#           A	    B	    C   	D	    F
#2019-05-01	False	False	False	False	False
#2019-05-02	False	False	False	False	True
#2019-05-03	False	False	False	False	False
#2019-05-04	False	False	False	False	False
#2019-05-05	False	False	False	False	True
#2019-05-06	False	False	False	False	False

df
#             A	        B	      C       	D	        F
#2019-05-01	0.593298	-1.412290	-0.008338	-0.069484	2.3
#2019-05-02	-0.157972	-0.690623	1.511215	1.441260	NaN
#2019-05-03	0.515979	-2.261321	-2.273262	1.047784	1.1
#2019-05-04	-0.875186	0.168660	-0.541034	0.078198	5.7
#2019-05-05	0.433342	-1.766760	0.679862	-0.006061	NaN
#2019-05-06	-0.757228	-1.345091	-1.260911	-0.097794	3.6
df.loc[df.isnull()['F'],:]
#           A	          B	        C	      D	        F
#2019-05-02	-0.157972	-0.690623	1.511215	1.441260	NaN
#2019-05-05	0.433342	-1.766760	0.679862	-0.006061	NaN

pd.to_datetime('20190501')
#Timestamp('2019-05-01 00:00:00')

df.drop(pd.to_datetime('20190501'))
#             A	        B	        C	        D	      F
#2019-05-02	-0.157972	-0.690623	1.511215	1.441260	NaN
#2019-05-03	0.515979	-2.261321	-2.273262	1.047784	1.1
#2019-05-04	-0.875186	0.168660	-0.541034	0.078198	5.7
#2019-05-05	0.433342	-1.766760	0.679862	-0.006061	NaN
#2019-05-06	-0.757228	-1.345091	-1.260911	-0.097794	3.6

df.drop([pd.to_datetime('20190502'),pd.to_datetime('20190504')])
#           A	          B	        C	      D	        F
#2019-05-01	0.593298	-1.412290	-0.008338	-0.069484	2.3
#2019-05-03	0.515979	-2.261321	-2.273262	1.047784	1.1
#2019-05-05	0.433342	-1.766760	0.679862	-0.006061	NaN
#2019-05-06	-0.757228	-1.345091	-1.260911	-0.097794	3.6

df.drop('F', axis = 1) # axis =0 for rows. axis = 1 for columns
#A	B	C	D
#2019-05-01	0.593298	-1.412290	-0.008338	-0.069484
#2019-05-02	-0.157972	-0.690623	1.511215	1.441260
#2019-05-03	0.515979	-2.261321	-2.273262	1.047784
#2019-05-04	-0.875186	0.168660	-0.541034	0.078198
#2019-05-05	0.433342	-1.766760	0.679862	-0.006061
#2019-05-06	-0.757228	-1.345091	-1.260911	-0.097794

df.drop(['B','C'], axis = 1)
#             A	        D	        F
#2019-05-01	0.593298	-0.069484	2.3
#2019-05-02	-0.157972	1.441260	NaN
#2019-05-03	0.515979	1.047784	1.1
#2019-05-04	-0.875186	0.078198	5.7
#2019-05-05	0.433342	-0.006061	NaN
#2019-05-06	-0.757228	-0.097794	3.6

################################### functions for data analytics ###########################

data = [[1.6, np.nan],
           [5.3, - 2.1],
           [np.nan, np.nan],
           [-1.5, 0.9]]
df = pd.DataFrame(data, columns = ['One','Two'], index = ['a','b','c','d'])
df
#      One	Two
#a	1.6	NaN
#b	5.3	-2.1
#c	NaN	NaN
#d	-1.5	0.9

df.sum(axis = 0) ### sum of columns
#One    5.4
#Two   -1.2
#dtype: float64

df.sum(axis = 1) ### sum of rows
a    1.6
b    3.2
c    0.0
d   -0.6
dtype: float64

df.sum(axis = 1, skipna=False)
#a    NaN
#b    3.2
#c    NaN
#d   -0.6
dtype: float64

df['One'].sum()
#5.4
df.loc['b'].sum()
#3.1999999999999997
### count
### min, max
### argmin, argmax
### idxmin, idxmax
### quantile
### sum
### mean
### median
### mad
### std, var
### cumsum
### cumprod

df2 = pd.DataFrame(np.random.randn(6,4),
                  columns = ['A','B','C','D'],
                  index = pd.date_range('20190511', periods = 6))
df2
#             A	       B	       C	       D
#2019-05-11	0.126847	-0.551651	-0.801475	1.459827
#2019-05-12	1.453071	-0.757490	0.139692	-0.487307
#2019-05-13	1.118221	0.164248	0.438368	1.307839
#2019-05-14	-0.436374	0.091264	1.056189	1.143240
#2019-05-15	0.173599	0.691031	0.722812	-0.995663
#2019-05-16	1.185154	0.563746	0.219653	0.469828

df2['A'].corr(df2['B']) # correlation coefficient 상관계수
#-0.1644204872766471
df2['B'].cov(df2['C']) # covariance 공분산
#0.2137025504007895


dates = df2.index
random_dates = np.random.permutation(dates)
df2 = df2.reindex(index = random_dates, columns = ['D','B','C','A'])
df2
#             D	       B	       C	       A
#2019-05-13	1.307839	0.164248	0.438368	1.118221
#2019-05-14	1.143240	0.091264	1.056189	-0.436374
#2019-05-11	1.459827	-0.551651	-0.801475	0.126847
#2019-05-15	-0.995663	0.691031	0.722812	0.173599
#2019-05-12	-0.487307	-0.757490	0.139692	1.453071
#2019-05-16	0.469828	0.563746	0.219653	1.185154

df2.sort_index(axis = 0)
#             D	       B	       C	       A
#2019-05-11	1.459827	-0.551651	-0.801475	0.126847
#2019-05-12	-0.487307	-0.757490	0.139692	1.453071
#2019-05-13	1.307839	0.164248	0.438368	1.118221
#2019-05-14	1.143240	0.091264	1.056189	-0.436374
#2019-05-15	-0.995663	0.691031	0.722812	0.173599
#2019-05-16	0.469828	0.563746	0.219653	1.185154

df2.sort_index(axis = 1)
#             A	       B	       C	       D
#2019-05-13	1.118221	0.164248	0.438368	1.307839
#2019-05-14	-0.436374	0.091264	1.056189	1.143240
#2019-05-11	0.126847	-0.551651	-0.801475	1.459827
#2019-05-15	0.173599	0.691031	0.722812	-0.995663
#2019-05-12	1.453071	-0.757490	0.139692	-0.487307
#2019-05-16	1.185154	0.563746	0.219653	0.469828

df2.sort_index(axis = 1, ascending = False)
#             D	       C	       B	       A
#2019-05-13	1.307839	0.438368	0.164248	1.118221
#2019-05-14	1.143240	1.056189	0.091264	-0.436374
#2019-05-11	1.459827	-0.801475	-0.551651	0.126847
#2019-05-15	-0.995663	0.722812	0.691031	0.173599
#2019-05-12	-0.487307	0.139692	-0.757490	1.453071
#2019-05-16	0.469828	0.219653	0.563746	1.185154

df2.sort_values(by = 'D')
#             D	       B	       C	       A
#2019-05-15	-0.995663	0.691031	0.722812	0.173599
#2019-05-12	-0.487307	-0.757490	0.139692	1.453071
#2019-05-16	0.469828	0.563746	0.219653	1.185154
#2019-05-14	1.143240	0.091264	1.056189	-0.436374
#2019-05-13	1.307839	0.164248	0.438368	1.118221
#2019-05-11	1.459827	-0.551651	-0.801475	0.126847

df2.sort_values(by = 'B', ascending = False)
#             D	       B	       C	       A
#2019-05-15	-0.995663	0.691031	0.722812	0.173599
#2019-05-16	0.469828	0.563746	0.219653	1.185154
#2019-05-13	1.307839	0.164248	0.438368	1.118221
#2019-05-14	1.143240	0.091264	1.056189	-0.436374
#2019-05-11	1.459827	-0.551651	-0.801475	0.126847
#2019-05-12	-0.487307	-0.757490	0.139692	1.453071

df2['E'] = np.random.randint(0, 6, size = 6)
df2['F'] = ['alpha', 'beta','gamma','alpha','beta','gamma']
df2
#             D	       B	       C	       A	       E	F
#2019-05-13	1.307839	0.164248	0.438368	1.118221	1	alpha
#2019-05-14	1.143240	0.091264	1.056189	-0.436374	0	beta
#2019-05-11	1.459827	-0.551651	-0.801475	0.126847	4	gamma
#2019-05-15	-0.995663	0.691031	0.722812	0.173599	0	alpha
#2019-05-12	-0.487307	-0.757490	0.139692	1.453071	5	beta
#2019-05-16	0.469828	0.563746	0.219653	1.185154	1	gamma

df2.sort_values(by = ['E','F'])
#             D	       B	       C	       A	       E	F
#2019-05-15	-0.995663	0.691031	0.722812	0.173599	0	alpha
#2019-05-14	1.143240	0.091264	1.056189	-0.436374	0	beta
#2019-05-13	1.307839	0.164248	0.438368	1.118221	1	alpha
#2019-05-16	0.469828	0.563746	0.219653	1.185154	1	gamma
#2019-05-11	1.459827	-0.551651	-0.801475	0.126847	4	gamma
#2019-05-12	-0.487307	-0.757490	0.139692	1.453071	5	beta

df2['F'].unique()
#array(['alpha', 'beta', 'gamma'], dtype=object)

df2['F'].value_counts()
#gamma    2
#beta     2
#alpha    2
#Name: F, dtype: int64

df2['F'].isin(['alpha','gamma'])
#2019-05-13     True
#2019-05-14    False
#2019-05-11     True
#2019-05-15     True
#2019-05-12    False
#2019-05-16     True
#Name: F, dtype: bool

df2.loc[df2['F'].isin(['alpha','gamma'])]
#             D	       B	       C	       A	       E      F
#2019-05-13	1.307839	0.164248	0.438368	1.118221	1	alpha
#2019-05-11	1.459827	-0.551651	-0.801475	0.126847	4	gamma
#2019-05-15	-0.995663	0.691031	0.722812	0.173599	0	alpha
#2019-05-16	0.469828	0.563746	0.219653	1.185154	1	gamma

df3 = pd.DataFrame(np.random.randn(4,3), columns = ['b','d','e'],
                  index = ["LA", "Chicago",'Seattle','Irvine'])
df3
#             b	       d	       e
#LA	       -0.343123	0.605282	-0.122967
#Chicago	0.769077	-0.467193	0.276840
#Seattle	-1.301829	0.132220	-0.652250
#Irvine	0.217595	-2.777186	1.226446

func = lambda x: x.max() - x.min()
df3.apply(func, axis = 0)
#b    2.070905
#d    3.382468
#e    1.878695
#dtype: float64
















